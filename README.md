
# ğŸ§  AI-Powered Customer Support System

A full-stack AI chatbot system that offers 24/7 customer support with automated feedback collection, learning from negative ratings, fine-tuning LLMs, and a CI/CD-ready architecture using Flask, SQLite, Docker, and LoRA-based retraining.

---

## ğŸš€ Features

- âœ… Conversational LLM chatbot using Mistral-7B-Instruct (GGUF + llama-cpp-python)
- âœ… Web UI built with Flask + Jinja2 (no JS framework)
- âœ… Chat session persistence using SQLite + SQLAlchemy
- âœ… User feedback collection (rating)
- âœ… Weekly feedback export and model fine-tuning with LoRA
- âœ… Automatic versioning: `mistral-finetuned_vX`
- âœ… Dockerized with `docker-compose`
- âœ… CI/CD-ready training loop with cron or GitHub Actions

---

## ğŸ—‚ Project Structure

```
customer_bot/
â”œâ”€â”€ app.py                    # Flask app with chat + feedback logic
â”œâ”€â”€ model_runner.py           # LLM model loading (llama-cpp-python)
â”œâ”€â”€ models.py                 # SQLAlchemy models for chat & feedback
â”œâ”€â”€ export_feedback.py        # Extracts low-rated chat data
â”œâ”€â”€ fine_tune/
â”‚   â””â”€â”€ train_lora.py         # Fine-tuning script using LoRA
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html            # Jinja2 UI template
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css             # Basic styling
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ mistral-fp16/         # Base HF model for fine-tuning
â”‚   â”œâ”€â”€ mistral-finetuned_v1/ # Fine-tuned model (merged)
â”‚   â””â”€â”€ .keep                 # Keeps folder structure in Git
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ Dockerfile                # App + training Docker image
â”œâ”€â”€ docker-compose.yaml       # Compose setup for web + cron jobs
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ’¬ Local Usage

### 1. Clone the project
```bash
git clone https://github.com/yourusername/ai-support-bot.git
cd ai-support-bot
```

### 2. Download model manually (GGUF format)
- Download from: https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF
- Place `.gguf` model under `./models/`

### 3. Run the chatbot
```bash
docker-compose up --build
```

Visit [http://localhost:5000](http://localhost:5000)

---

## ğŸ” Weekly Auto-Retrain Workflow

- `export_feedback.py` extracts chats with ratings â‰¤2
- `train_lora.py` fine-tunes on them using LoRA
- Merged model is saved as `models/mistral-finetuned_vX/`
- Can be converted to GGUF for inference deployment

---

## ğŸ”§ CI/CD Friendly

Integrate with GitHub Actions, Jenkins, or GitLab CI:

```yaml
steps:
  - run: python export_feedback.py
  - run: python fine_tune/train_lora.py
  - run: docker build -t yourregistry/ai-support-bot:vX .
  - run: docker push yourregistry/ai-support-bot:vX
```

---

## ğŸ§‘â€ğŸ’» Credits

Built by Akshay Aithal using:
- Flask
- llama-cpp-python
- PEFT + LoRA
